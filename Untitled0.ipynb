{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ishidafuu/AquesTalk10UnitySample/blob/master/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShaTNyWycTVL",
        "colab_type": "code",
        "outputId": "ed32065f-6af0-4c3c-bfcb-fe40ad8ea737",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist import input_data \n",
        "\n",
        "# MINSTの手書き画像データを読み込む --- (*1)\n",
        "mnist = input_data.read_data_sets(\"mnist/\", one_hot=True)\n",
        "\n",
        "pixels = 28 * 28 # 28x28ピクセル\n",
        "nums = 10 # 0-9の10クラスに分ける\n",
        "\n",
        "# プレースホルダを定義 --- (*2)\n",
        "x  = tf.placeholder(tf.float32, shape=(None, pixels), name=\"x\") # 画像データ\n",
        "y_ = tf.placeholder(tf.float32, shape=(None, nums), name=\"y_\")  # 正解ラベル \n",
        "\n",
        "# 重みとバイアスを初期化する関数 --- (*3)\n",
        "def weight_variable(name, shape):\n",
        "    W_init = tf.truncated_normal(shape, stddev=0.1)\n",
        "    W = tf.Variable(W_init, name=\"W_\"+name)\n",
        "    return W\n",
        "def bias_variable(name, size):\n",
        "    b_init = tf.constant(0.1, shape=[size])\n",
        "    b = tf.Variable(b_init, name=\"b_\"+name)\n",
        "    return b\n",
        "\n",
        "# 畳み込みを行う関数 --- (*4)\n",
        "def conv2d(x, W):\n",
        "    return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')\n",
        "# 最大プーリングを行う関数 --- (*5)\n",
        "def max_pool(x):\n",
        "    return tf.nn.max_pool(x, ksize=[1,2,2,1],\n",
        "        strides=[1,2,2,1], padding='SAME')\n",
        "\n",
        "# 畳み込み層1 --- (*6)\n",
        "with tf.name_scope('conv1') as scope:\n",
        "    W_conv1 = weight_variable('conv1', [5, 5, 1, 32])\n",
        "    b_conv1 = bias_variable('conv1', 32)\n",
        "    x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
        "    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
        "\n",
        "# プーリング層1 ---- (*7)\n",
        "with tf.name_scope('pool1') as scope:\n",
        "    h_pool1 = max_pool(h_conv1)\n",
        "\n",
        "# 畳み込み層2 --- (*8)\n",
        "with tf.name_scope('conv2') as scope:\n",
        "    W_conv2 = weight_variable('conv2', [5, 5, 32, 64])\n",
        "    b_conv2 = bias_variable('conv2', 64)\n",
        "    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
        "\n",
        "# プーリング層2 --- (*9)\n",
        "with tf.name_scope('pool2') as scope:\n",
        "    h_pool2 = max_pool(h_conv2)\n",
        "\n",
        "# 全結合レイヤー --- (*10)\n",
        "with tf.name_scope('fully_connected') as scope:\n",
        "    n = 7 * 7 * 64\n",
        "    W_fc = weight_variable('fc', [n, 1024])\n",
        "    b_fc = bias_variable('fc', 1024)\n",
        "    h_pool2_flat = tf.reshape(h_pool2, [-1, n])\n",
        "    h_fc = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc) + b_fc)        \n",
        "\n",
        "# ドロップアウト(過剰適合)を排除 --- (*11)\n",
        "with tf.name_scope('dropout') as scope:\n",
        "    keep_prob = tf.placeholder(tf.float32)\n",
        "    h_fc_drop = tf.nn.dropout(h_fc, keep_prob)\n",
        "\n",
        "# 読み出し層 --- (*12)\n",
        "with tf.name_scope('readout') as scope:\n",
        "    W_fc2 = weight_variable('fc2', [1024, 10])\n",
        "    b_fc2 = bias_variable('fc2', 10)\n",
        "    y_conv = tf.nn.softmax(tf.matmul(h_fc_drop, W_fc2) + b_fc2)\n",
        "\n",
        "# モデルの学習 --- (*13)\n",
        "with tf.name_scope('loss') as scope:\n",
        "    cross_entoropy = -tf.reduce_sum(y_ * tf.log(y_conv))\n",
        "with tf.name_scope('training') as scope:\n",
        "    optimizer = tf.train.AdamOptimizer(1e-4)\n",
        "    train_step = optimizer.minimize(cross_entoropy)\n",
        "\n",
        "# モデルの評価 --- (*14)\n",
        "with tf.name_scope('predict') as scope:\n",
        "    predict_step = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
        "    accuracy_step = tf.reduce_mean(tf.cast(predict_step, tf.float32))\n",
        "\n",
        "# feed_dictの設定 --- (*15)\n",
        "def set_feed(images, labels, prob):\n",
        "    return {x: images, y_: labels, keep_prob: prob}\n",
        "\n",
        "# セッションを開始 --- (*16)\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    # TensorBoardへの書き込み準備\n",
        "    tw = tf.summary.FileWriter('log_dir', graph=sess.graph)\n",
        "    # テスト用のフィードを生成\n",
        "    test_fd = set_feed(mnist.test.images, mnist.test.labels, 1)\n",
        "    # 訓練を開始 ---- (*17)\n",
        "    for step in range(10000):\n",
        "        batch = mnist.train.next_batch(50)\n",
        "        fd = set_feed(batch[0], batch[1], 0.5)\n",
        "        _, loss = sess.run([train_step, cross_entoropy], feed_dict=fd)\n",
        "        if step % 100 == 0:\n",
        "            acc = sess.run(accuracy_step, feed_dict=test_fd)\n",
        "            print(\"step=\", step, \"loss=\", loss, \"acc=\", acc)\n",
        "    # 最終結果を表示\n",
        "    acc = sess.run(accuracy_step, feed_dict=test_fd)\n",
        "    print(\"正解率=\", acc)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0706 08:44:34.037044 139848231831424 deprecation.py:323] From <ipython-input-1-565aa75a9554>:5: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "W0706 08:44:34.039108 139848231831424 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "W0706 08:44:34.045970 139848231831424 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "W0706 08:44:39.479611 139848231831424 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "Extracting mnist/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0706 08:44:39.898509 139848231831424 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "W0706 08:44:39.904725 139848231831424 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "Extracting mnist/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0706 08:44:40.512504 139848231831424 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting mnist/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting mnist/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0706 08:44:40.793610 139848231831424 deprecation.py:506] From <ipython-input-1-565aa75a9554>:64: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step= 0 loss= 751.4404 acc= 0.0863\n",
            "step= 100 loss= 66.75629 acc= 0.8265\n",
            "step= 200 loss= 21.672304 acc= 0.9034\n",
            "step= 300 loss= 17.38222 acc= 0.9175\n",
            "step= 400 loss= 22.614674 acc= 0.9339\n",
            "step= 500 loss= 21.943726 acc= 0.9442\n",
            "step= 600 loss= 9.260731 acc= 0.9449\n",
            "step= 700 loss= 12.355413 acc= 0.9506\n",
            "step= 800 loss= 7.6481566 acc= 0.9551\n",
            "step= 900 loss= 5.9437146 acc= 0.9575\n",
            "step= 1000 loss= 6.9625993 acc= 0.9563\n",
            "step= 1100 loss= 8.491844 acc= 0.9625\n",
            "step= 1200 loss= 6.0642433 acc= 0.9652\n",
            "step= 1300 loss= 9.403311 acc= 0.9648\n",
            "step= 1400 loss= 6.767106 acc= 0.9641\n",
            "step= 1500 loss= 5.5386252 acc= 0.9668\n",
            "step= 1600 loss= 10.226733 acc= 0.9689\n",
            "step= 1700 loss= 11.411598 acc= 0.9697\n",
            "step= 1800 loss= 11.475017 acc= 0.9712\n",
            "step= 1900 loss= 6.363553 acc= 0.9729\n",
            "step= 2000 loss= 9.948045 acc= 0.9742\n",
            "step= 2100 loss= 3.3502648 acc= 0.9756\n",
            "step= 2200 loss= 7.772358 acc= 0.974\n",
            "step= 2300 loss= 0.6516748 acc= 0.9748\n",
            "step= 2400 loss= 7.6208463 acc= 0.9758\n",
            "step= 2500 loss= 7.359657 acc= 0.975\n",
            "step= 2600 loss= 12.023389 acc= 0.9777\n",
            "step= 2700 loss= 8.433172 acc= 0.9746\n",
            "step= 2800 loss= 5.9694405 acc= 0.9769\n",
            "step= 2900 loss= 3.2773104 acc= 0.9789\n",
            "step= 3000 loss= 5.670078 acc= 0.9803\n",
            "step= 3100 loss= 1.0271856 acc= 0.9811\n",
            "step= 3200 loss= 5.4251294 acc= 0.9803\n",
            "step= 3300 loss= 8.638043 acc= 0.9798\n",
            "step= 3400 loss= 7.546053 acc= 0.9799\n",
            "step= 3500 loss= 1.6394193 acc= 0.9798\n",
            "step= 3600 loss= 6.623056 acc= 0.9836\n",
            "step= 3700 loss= 7.0383315 acc= 0.9831\n",
            "step= 3800 loss= 0.9570178 acc= 0.9834\n",
            "step= 3900 loss= 6.1482687 acc= 0.9837\n",
            "step= 4000 loss= 3.9708307 acc= 0.9833\n",
            "step= 4100 loss= 1.2174932 acc= 0.9848\n",
            "step= 4200 loss= 4.968498 acc= 0.9853\n",
            "step= 4300 loss= 2.537612 acc= 0.9846\n",
            "step= 4400 loss= 0.7195615 acc= 0.9843\n",
            "step= 4500 loss= 2.8305774 acc= 0.984\n",
            "step= 4600 loss= 5.4588966 acc= 0.9834\n",
            "step= 4700 loss= 1.5372607 acc= 0.9864\n",
            "step= 4800 loss= 2.075123 acc= 0.9853\n",
            "step= 4900 loss= 1.5488247 acc= 0.9857\n",
            "step= 5000 loss= 9.710391 acc= 0.9864\n",
            "step= 5100 loss= 3.675771 acc= 0.9861\n",
            "step= 5200 loss= 3.0991905 acc= 0.987\n",
            "step= 5300 loss= 5.1773114 acc= 0.9868\n",
            "step= 5400 loss= 1.7437973 acc= 0.9869\n",
            "step= 5500 loss= 8.44319 acc= 0.9859\n",
            "step= 5600 loss= 2.4304147 acc= 0.9865\n",
            "step= 5700 loss= 1.1352451 acc= 0.9874\n",
            "step= 5800 loss= 1.113807 acc= 0.9881\n",
            "step= 5900 loss= 4.2362723 acc= 0.9877\n",
            "step= 6000 loss= 0.41520795 acc= 0.9879\n",
            "step= 6100 loss= 2.8077152 acc= 0.9886\n",
            "step= 6200 loss= 7.1685295 acc= 0.9898\n",
            "step= 6300 loss= 1.6534044 acc= 0.9878\n",
            "step= 6400 loss= 0.59580684 acc= 0.9862\n",
            "step= 6500 loss= 7.222303 acc= 0.988\n",
            "step= 6600 loss= 1.0860124 acc= 0.9882\n",
            "step= 6700 loss= 0.6670277 acc= 0.9896\n",
            "step= 6800 loss= 0.3091426 acc= 0.9881\n",
            "step= 6900 loss= 3.1184752 acc= 0.9885\n",
            "step= 7000 loss= 1.1061616 acc= 0.9878\n",
            "step= 7100 loss= 3.9143407 acc= 0.989\n",
            "step= 7200 loss= 0.5305437 acc= 0.9893\n",
            "step= 7300 loss= 4.511754 acc= 0.9887\n",
            "step= 7400 loss= 0.79734844 acc= 0.9884\n",
            "step= 7500 loss= 0.19282155 acc= 0.9888\n",
            "step= 7600 loss= 0.21335024 acc= 0.989\n",
            "step= 7700 loss= 2.2091067 acc= 0.9901\n",
            "step= 7800 loss= 3.9943547 acc= 0.9902\n",
            "step= 7900 loss= 1.5483098 acc= 0.9897\n",
            "step= 8000 loss= 2.5441897 acc= 0.9895\n",
            "step= 8100 loss= 0.3944217 acc= 0.9881\n",
            "step= 8200 loss= 1.040319 acc= 0.9895\n",
            "step= 8300 loss= 2.9162436 acc= 0.9901\n",
            "step= 8400 loss= 1.4093663 acc= 0.99\n",
            "step= 8500 loss= 0.8711795 acc= 0.9913\n",
            "step= 8600 loss= 0.18048659 acc= 0.9908\n",
            "step= 8700 loss= 6.264757 acc= 0.9912\n",
            "step= 8800 loss= 0.8455162 acc= 0.991\n",
            "step= 8900 loss= 0.2697836 acc= 0.99\n",
            "step= 9000 loss= 1.1102422 acc= 0.9894\n",
            "step= 9100 loss= 4.645318 acc= 0.9898\n",
            "step= 9200 loss= 1.4350647 acc= 0.9899\n",
            "step= 9300 loss= 0.72660464 acc= 0.9915\n",
            "step= 9400 loss= 1.0998757 acc= 0.991\n",
            "step= 9500 loss= 0.20772666 acc= 0.9896\n",
            "step= 9600 loss= 4.5819063 acc= 0.99\n",
            "step= 9700 loss= 6.627838 acc= 0.9906\n",
            "step= 9800 loss= 1.2788657 acc= 0.9901\n",
            "step= 9900 loss= 2.3788462 acc= 0.9908\n",
            "正解率= 0.99\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgM3E2ditX2H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwybpR1DtYQT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OC78-Mo5cbg1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}